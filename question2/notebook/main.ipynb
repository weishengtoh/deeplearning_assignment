{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import os\n",
    "import io\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from tensorflow.data.experimental import AUTOTUNE\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove tensorflow warnings and define the logger\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)-15s %(message)s\")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the class to extract the raw data and convert them into TFRecords\n",
    "---\n",
    "\n",
    "Converting the data to TFRecords helps to optimise the data pipeline, which makes the overall training process faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExtractor():\n",
    "\n",
    "    '''Define the DataExtractor class used to extract raw data from zip and convert to TFRecords'''\n",
    "\n",
    "    def __init__(self, random_state=42, test_size=0.1, val_size=0.1):\n",
    "        self.random_state = random_state\n",
    "        self.test_size = test_size\n",
    "        self.val_size = val_size\n",
    "\n",
    "    @staticmethod\n",
    "    def _bytes_feature(value):\n",
    "        '''Boilerplate code to convert an image into Tensorflow Feature'''\n",
    "        if isinstance(value, type(tf.constant(0))):\n",
    "            value = value.numpy()\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    @staticmethod\n",
    "    def _int64_feature(value):\n",
    "        '''Boilerplate code to convert an image label into Tensorflow Feature'''\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    \n",
    "    @staticmethod\n",
    "    def serialize_example(image, label):\n",
    "\n",
    "        '''Function to convert data into tf.train.Example format and serialize it'''\n",
    "\n",
    "        image_string = open(image, 'rb').read()\n",
    "        \n",
    "        image_shape = tf.io.decode_image(image_string, channels=3, expand_animations=False).shape\n",
    "    \n",
    "        feature = {\n",
    "            'image_raw': DataExtractor._bytes_feature(image_string),\n",
    "            'label': DataExtractor._int64_feature(label),\n",
    "            'height': DataExtractor._int64_feature(image_shape[0]),\n",
    "            'width': DataExtractor._int64_feature(image_shape[1]),\n",
    "            'depth': DataExtractor._int64_feature(image_shape[2]),  \n",
    "        }\n",
    "\n",
    "        example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "        return example_proto.SerializeToString()\n",
    "\n",
    "    def extract_data(self, rawpath, datafolder) -> list:\n",
    "\n",
    "        '''Function to extract data from zip and returns the labels'''\n",
    "\n",
    "        self.rawpath = rawpath\n",
    "        self.datafolder = pathlib.Path(datafolder)\n",
    "\n",
    "        with ZipFile(self.rawpath, 'r') as file:\n",
    "            file.extractall(path=self.datafolder)\n",
    "\n",
    "        self.labels = [path.name for path in self.datafolder.glob('*') if path.is_dir()]\n",
    "\n",
    "        return self.labels\n",
    "\n",
    "    def generate_tfrecords(self, tfrfolder):\n",
    "        \n",
    "        '''Function to segregate data into train/val/test splits and generate TFRecords'''\n",
    "\n",
    "        self.tfrfolder = pathlib.Path(tfrfolder)\n",
    "        self.tfrfolder.mkdir(exist_ok=True)\n",
    "\n",
    "        segregated_data = {\n",
    "                            'train': {}, \n",
    "                            'val': {}, \n",
    "                            'test': {}\n",
    "                        }\n",
    "        \n",
    "        for label in self.labels:\n",
    "            image_list = [image for image in self.datafolder.joinpath(label).iterdir()]\n",
    "\n",
    "\n",
    "            train_img, test_img = train_test_split(\n",
    "                                        image_list, \n",
    "                                        test_size=self.test_size, \n",
    "                                        shuffle=True, \n",
    "                                        random_state=self.random_state)\n",
    "\n",
    "            train_img, val_img = train_test_split(\n",
    "                                        train_img, \n",
    "                                        test_size=self.val_size/(1-self.test_size), \n",
    "                                        shuffle=True, \n",
    "                                        random_state=self.random_state)\n",
    "\n",
    "            segregated_data['train'][label] = train_img\n",
    "            segregated_data['val'][label] = val_img\n",
    "            segregated_data['test'][label] = test_img\n",
    "\n",
    "        for segment, labels in segregated_data.items():\n",
    "            recordfile = os.path.join(self.tfrfolder, f'{segment}.tfrecord')\n",
    "\n",
    "            with tf.io.TFRecordWriter(recordfile) as writer:\n",
    "                for label, img_list in labels.items():\n",
    "                    for img in img_list:\n",
    "                        label_cat = self.labels.index(label)\n",
    "                        serialized_example = DataExtractor.serialize_example(img, label_cat)\n",
    "                        writer.write(serialized_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the class to load the data and perform data augmentation\n",
    "---\n",
    "Data augmentation is only applied to training data, hence we should not include it in the model definition.  \n",
    "We can make use of prefetching to speed up the data pipeline as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "\n",
    "    '''Function to load the data from TFRecords and perform data augmentation'''\n",
    "\n",
    "    def __init__(self, img_size, batch_size, buffer_size, drop_remainder=True, random_seed=42):\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_size = buffer_size\n",
    "        self.drop_remainder = drop_remainder\n",
    "        self.img_size = img_size\n",
    "        self.random_seed = random_seed\n",
    "        self.rng = tf.random.Generator.from_seed(self.random_seed, alg='philox')\n",
    "\n",
    "        logdir = \"logs/train_im/\"\n",
    "        self.file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_image(example_proto):\n",
    "        \n",
    "        '''Function to parse the image, applied to all train/val/test data'''\n",
    "\n",
    "        feature_description = {\n",
    "            'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "            'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'depth': tf.io.FixedLenFeature([], tf.int64),  \n",
    "        }\n",
    "\n",
    "        features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "        \n",
    "        image = tf.io.decode_image(features['image_raw'], channels=3, expand_animations = False)\n",
    "        image = tf.image.resize(image, IMG_SIZE)\n",
    "\n",
    "        label = tf.cast(features['label'], tf.int32)\n",
    "\n",
    "        return (image, label)\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_to_image(figure):\n",
    "\n",
    "        '''Boilerplate code to save a matplotlib figure to png image'''\n",
    "\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_image(buf.getvalue(), channels=4, expand_animations=False)\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "\n",
    "    def wrapper_image_augment(self, image, label):\n",
    "        \n",
    "        '''Wrapper function containing the data augmentation code'''\n",
    "\n",
    "        seed = self.rng.make_seeds(2)[0]\n",
    "\n",
    "        def image_augment(image, label, seed):\n",
    "            \n",
    "            # Uncomment these cells to experiment with data augmentation\n",
    "\n",
    "            # image = tf.image.stateless_random_flip_left_right(image, seed=seed)\n",
    "            # image = tf.image.stateless_random_flip_up_down(image, seed=seed)\n",
    "            # image = tf.image.rot90(image)\n",
    "            # image = tf.image.stateless_random_brightness(image, max_delta=0.1, seed=seed)\n",
    "            # image = tf.image.stateless_random_hue(image, max_delta=0.2, seed=seed)\n",
    "            # image = tf.image.stateless_random_saturation(image, lower=0.5, upper=0.7, seed=seed)\n",
    "            # image = tf.image.stateless_random_contrast(image, lower=0.4, upper=0.6, seed=seed)\n",
    "            \n",
    "            return (image, label)\n",
    "\n",
    "        return image_augment(image, label, seed)\n",
    "\n",
    "    def preprocess_data(self, data_path):\n",
    "\n",
    "        '''Function used to preprocess val/test data - augmentation not applied'''\n",
    "\n",
    "        dataset = tf.data.TFRecordDataset(data_path)\\\n",
    "                    .map(DataLoader.parse_image, num_parallel_calls=AUTOTUNE)\\\n",
    "                    .shuffle(self.buffer_size, self.random_seed)\\\n",
    "                    .batch(self.batch_size, drop_remainder=self.drop_remainder)\\\n",
    "                    .repeat()\\\n",
    "                    .prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def preprocess_train(self, train_path):\n",
    "\n",
    "        '''Function used to preprocess training data - augmentation applied'''\n",
    "\n",
    "        dataset = tf.data.TFRecordDataset(train_path)\\\n",
    "                    .map(DataLoader.parse_image, num_parallel_calls=AUTOTUNE)\\\n",
    "                    .map(self.wrapper_image_augment, num_parallel_calls=AUTOTUNE)\\\n",
    "                    .shuffle(self.buffer_size, self.random_seed)\\\n",
    "                    .batch(self.batch_size, drop_remainder=self.drop_remainder)\\\n",
    "                    .repeat()\\\n",
    "                    .prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def read_tfrecords(self, train_path, val_path, test_path):\n",
    "\n",
    "        '''Function to read TFRecords from path and apply preprocessing'''\n",
    "\n",
    "        self.train_data = self.preprocess_train(train_path)\n",
    "        self.val_data = self.preprocess_data(val_path)\n",
    "        self.test_data = self.preprocess_data(test_path)\n",
    "\n",
    "        return (self.train_data, self.val_data, self.test_data)\n",
    "\n",
    "    def plot_train_images(self, steps, labels):\n",
    "\n",
    "        '''Function to generate training images to be visualised in TensorBoard'''\n",
    "\n",
    "        data_X = []\n",
    "        data_y = []\n",
    "        for X, y in self.train_data.take(steps).unbatch().as_numpy_iterator():\n",
    "            data_X.append(X)\n",
    "            data_y.append(y)\n",
    "\n",
    "        df = pd.DataFrame({'X': data_X, 'y': data_y})\n",
    "\n",
    "        grid_size = np.ceil(np.sqrt(len(df))).astype(int)\n",
    "        df['label_y'] = df['y'].map(lambda x: labels[x])\n",
    "\n",
    "        fig = plt.figure(figsize=(25, 25))\n",
    "\n",
    "        grid = ImageGrid(fig, 111, nrows_ncols=(grid_size, grid_size), axes_pad=0.3)\n",
    "\n",
    "        for idx in range(len(df)):\n",
    "            img = df['X'][idx] /255.0\n",
    "            grid[idx].set_axis_off()\n",
    "            grid[idx].set_title(df['label_y'][idx])\n",
    "            grid[idx].imshow(img)\n",
    "        \n",
    "        img = DataLoader.plot_to_image(fig)\n",
    "\n",
    "        with self.file_writer.as_default():\n",
    "            tf.summary.image(\"Training Images\", img, step=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "---\n",
    "ResNet50 is used as the feature extractor, and a simple Dense layer ontop of a GlobalAveragePooling2D layer is used as the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "\n",
    "    '''\n",
    "    Define an image classification model using ResNet50 as feature extractor\n",
    "    Subclass from tensorflow.keras.models.Model\n",
    "    '''\n",
    "\n",
    "    def __init__(self, n_classes, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Define the feature extractor and preprocessing fn\n",
    "        self.base = resnet50.ResNet50(\n",
    "                    input_shape=(224, 224, 3), \n",
    "                    include_top=False, \n",
    "                    weights='imagenet')\n",
    "        self.preprocess = resnet50.preprocess_input\n",
    "\n",
    "        # Freeze the base model\n",
    "        for layer in self.base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Define the classifier\n",
    "        self.global_pool = GlobalAveragePooling2D()\n",
    "        self.classifier = Dense(n_classes)\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        x = self.preprocess(input_tensor) \n",
    "        x = self.base(x)\n",
    "        x = self.global_pool(x)\n",
    "\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the training steps in a ModelTrainer Class\n",
    "---\n",
    "This is the most complicated step in the entire workflow.  \n",
    "\n",
    "Here we have defined `generate_confusion_matrix` and `error_analysis` to produce visualisation at the end of each epoch.  \n",
    "More details at further down in the notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer():\n",
    "\n",
    "    '''Define a ModelTrainer class containing all the steps required to train the model'''\n",
    "\n",
    "    def __init__(self, model, train_data, val_data, optimizer, epochs, steps_per_epoch_train, steps_per_epoch_val, labels):\n",
    "        self.model = model\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.steps_per_epoch_train = steps_per_epoch_train\n",
    "        self.steps_per_epoch_val = steps_per_epoch_val\n",
    "        self.labels = labels\n",
    "        \n",
    "        # Used to save the model at regular intervals\n",
    "        self.checkpoint = tf.train.Checkpoint(optimizer=self.optimizer, model=self.model)\n",
    "        self.checkpoint_manager = tf.train.CheckpointManager(self.checkpoint, './tf_ckpts', max_to_keep = 5)\n",
    "\n",
    "        # Define the train and validation metrics\n",
    "        self.loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        self.train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.train_loss = tf.keras.metrics.Mean(name='loss')\n",
    "        self.val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "\n",
    "        # Define the directory and summary writer for TensorBoard logs\n",
    "        log_dir_train = 'logs/train/'\n",
    "        log_dir_val = 'logs/val/' \n",
    "        log_dir_cm = 'logs/confusion_matrix/' \n",
    "        log_dir_ea = 'logs/error_analysis/' \n",
    "\n",
    "        self.train_summary_writer = tf.summary.create_file_writer(log_dir_train)\n",
    "        self.val_summary_writer = tf.summary.create_file_writer(log_dir_val)\n",
    "        self.confusion_matrix_writer = tf.summary.create_file_writer(log_dir_cm)\n",
    "        self.error_analysis_writer = tf.summary.create_file_writer(log_dir_ea)\n",
    "\n",
    "        # Define an epoch counter to continue graph when training restarts\n",
    "        self.epoch_counter = 1\n",
    "        self.best_epoch_counter = 1\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_to_image(figure):\n",
    "\n",
    "        '''Boilerplate code to convert matplotlib image to png'''\n",
    "\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_image(buf.getvalue(), channels=4, expand_animations=False)\n",
    "\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def generate_confusion_matrix(self, val_y, logits, step):\n",
    "\n",
    "        '''Function to generate the confusion matrix'''\n",
    "\n",
    "        # Apply the activation function and obtain the prediction\n",
    "        val_pred = tf.nn.softmax(logits)   \n",
    "        val_pred = np.argmax(val_pred, axis=1)\n",
    "\n",
    "        # Generate the confusion matrix figure\n",
    "        display = ConfusionMatrixDisplay.from_predictions(val_y, val_pred, display_labels=self.labels)\n",
    "        display.ax_.tick_params('x', labelrotation=45.0)\n",
    "        fig = display.figure_\n",
    "        fig.tight_layout(pad=3.0)\n",
    "\n",
    "        # Convert the matplotlib figure to png\n",
    "        image = ModelTrainer.plot_to_image(fig)\n",
    "\n",
    "        # Write the png image to TensorBoard logs\n",
    "        with self.confusion_matrix_writer.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", image, step=step)\n",
    "\n",
    "    def error_analysis(self, val_X, val_y, logits, step):\n",
    "        \n",
    "        '''Function to display all validation images wrongly classified'''\n",
    "\n",
    "        # Apply activation and obtain predictions\n",
    "        val_pred = tf.nn.softmax(logits)  \n",
    "        val_pred = np.argmax(val_pred, axis=1)\n",
    "        \n",
    "        # Compare predictions to ground truth and obtain misclassified images\n",
    "        misclass_X = []\n",
    "        misclass_y = []\n",
    "\n",
    "        for idx, instance in enumerate(zip(val_X, val_y)):\n",
    "            val_X, val_y = instance\n",
    "            if val_y != val_pred[idx]:\n",
    "                misclass_X.append(val_X)\n",
    "                misclass_y.append(val_pred[idx])\n",
    "\n",
    "        misclass_df = pd.DataFrame({'misclass_X': misclass_X, 'misclass_y': misclass_y})\n",
    "        \n",
    "        # Set display grid \n",
    "        grid_size = np.ceil(np.sqrt(len(misclass_df))).astype(int)\n",
    "        \n",
    "        # Obtain predicted labels for images \n",
    "        misclass_df['val_label'] = misclass_df['misclass_y'].map(lambda x: self.labels[x])\n",
    "\n",
    "        # Obtain matplotlib figure of misclassified images\n",
    "        fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "        grid = ImageGrid(fig, 111, nrows_ncols=(grid_size, grid_size), axes_pad=0.3)\n",
    "\n",
    "        for idx in range(len(misclass_df)):\n",
    "            img = misclass_df['misclass_X'][idx] / 255.0\n",
    "\n",
    "            grid[idx].imshow(img)\n",
    "            grid[idx].set_axis_off()\n",
    "            grid[idx].set_title(misclass_df['val_label'][idx])\n",
    "\n",
    "        # Convert matplotlib figure to png\n",
    "        fig.tight_layout(pad=3.0)\n",
    "        image = ModelTrainer.plot_to_image(fig)\n",
    "\n",
    "        # Write the png image to TensorBoard logs\n",
    "        with self.error_analysis_writer.as_default():\n",
    "            tf.summary.image(\"Error Analysis\", image, step=step)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        \n",
    "        '''Function to test on a batch of training data'''\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Perform automatic differentiation\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(inputs, training=True)\n",
    "            step_loss = self.loss_fn(labels, logits)\n",
    "\n",
    "        # Update the trainable variables based on the optimizer and gradients calculated\n",
    "        gradients = tape.gradient(step_loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # Update the train accuracy and loss\n",
    "        self.train_acc_metric.update_state(labels, logits)\n",
    "        self.train_loss.update_state(step_loss)\n",
    "\n",
    "        return (step_loss, logits)\n",
    "\n",
    "    def val_step(self, data):\n",
    "\n",
    "        '''Function to test on a batch of validation data'''\n",
    "\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Obtain the logits and loss\n",
    "        logits = self.model(inputs, training=False)\n",
    "        step_loss = self.loss_fn(labels, logits)\n",
    "\n",
    "        # Update the validation accuracy and loss\n",
    "        self.val_acc_metric.update_state(labels, logits)\n",
    "        self.val_loss.update_state(step_loss)\n",
    "\n",
    "        return (step_loss, logits)\n",
    "\n",
    "    def predict_step(self, data):\n",
    "\n",
    "        '''Function to predict on a batch of test data'''\n",
    "\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Obtain the logits and loss\n",
    "        logits = self.model(inputs, training=False)\n",
    "        step_loss = self.loss_fn(labels, logits)\n",
    "\n",
    "        return (step_loss, logits)\n",
    "    \n",
    "    def train_and_evaluate(self):\n",
    "\n",
    "        '''Function to perform training and validation over the entire datasets'''\n",
    "\n",
    "        logger.info('[INFO] Start Training')\n",
    "        \n",
    "        # Check if checkpoints exists, and restore training from checkpoints if available.\n",
    "        self.checkpoint.restore(self.checkpoint_manager.latest_checkpoint)\n",
    "        if self.checkpoint_manager.latest_checkpoint:\n",
    "\n",
    "            # Continue graph from best epoch\n",
    "            self.epoch_counter = self.best_epoch_counter\n",
    "            logger.info(f'[INFO] Restoring training from epoch: {self.epoch_counter} from ckpt: {self.checkpoint_manager.latest_checkpoint}')\n",
    "        else:\n",
    "            logger.info(f'[INFO] Training from scratch')\n",
    "\n",
    "            # Reset epoch counter if training from scratch\n",
    "            self.epoch_counter = 1\n",
    "            self.best_epoch_counter = 1\n",
    "    \n",
    "        patience = 5 # wait 5 epochs to see if there is any improvement before terminating training\n",
    "        wait = 0 \n",
    "        best = 0\n",
    "\n",
    "        # Run the training over the specified no. of epochs\n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            # Perform training on a batch of training data\n",
    "            logger.info(f'[INFO] Performing training on epoch: {self.epoch_counter}')\n",
    "            train_count = self.steps_per_epoch_train\n",
    "            for step, batch in enumerate(self.train_data):\n",
    "                if train_count == 0:\n",
    "                    break\n",
    "                step_loss, logits = self.train_step(batch) \n",
    "                train_count -= 1\n",
    "            \n",
    "            # Perform validation on a batch of validation data\n",
    "            logger.info(f'[INFO] Performing validation on epoch: {self.epoch_counter}')\n",
    "            \n",
    "            val_X = []\n",
    "            val_y = []\n",
    "            logit_list = []\n",
    "            \n",
    "            val_count = self.steps_per_epoch_val\n",
    "            for step, batch in enumerate(self.val_data):\n",
    "                \n",
    "                if val_count == 0:\n",
    "                    break\n",
    "\n",
    "                step_loss, logits = self.val_step(batch)\n",
    "\n",
    "                X, y = batch\n",
    "                val_X.extend(X)\n",
    "                val_y.extend(y)\n",
    "                logit_list.extend(logits)\n",
    "\n",
    "                val_count -= 1\n",
    "            \n",
    "            # Obtain the train and validation accuracy for the epoch\n",
    "            epoch_train_acc = self.train_acc_metric.result()\n",
    "            epoch_train_loss = self.train_loss.result()\n",
    "            epoch_val_acc = self.val_acc_metric.result()\n",
    "            epoch_val_loss = self.val_loss.result()\n",
    "            \n",
    "            # Generate confusion matrix and error analysis at end of each epoch\n",
    "            self.generate_confusion_matrix(val_y, logit_list, self.epoch_counter)\n",
    "            self.error_analysis(val_X, val_y, logit_list, self.epoch_counter)\n",
    "\n",
    "            # Log the results to console\n",
    "            logger.info(f'[INFO] Epoch: {self.epoch_counter} | loss: {epoch_train_loss:0.2f} | accuracy: {epoch_train_acc:0.2f} | val_loss: {epoch_val_loss:0.2f} | val_accuracy: {epoch_val_acc:0.2f}')\n",
    "\n",
    "            # Not really needed yet... Just in case.\n",
    "            epoch_logs = {\n",
    "                            'loss': epoch_train_loss, \n",
    "                            'accuracy': epoch_train_acc, \n",
    "                            'val_loss': epoch_val_loss, \n",
    "                            'val_accuracy': epoch_val_acc\n",
    "                        }\n",
    "\n",
    "            # Write the metrics to summary for TensorBoard\n",
    "            with self.train_summary_writer.as_default():\n",
    "                tf.summary.scalar('loss', epoch_train_loss, step=self.epoch_counter)\n",
    "                tf.summary.scalar('accuracy', epoch_train_acc, step=self.epoch_counter)\n",
    "\n",
    "            with self.val_summary_writer.as_default():\n",
    "                tf.summary.scalar('loss', epoch_val_loss, step=self.epoch_counter)\n",
    "                tf.summary.scalar('accuracy', epoch_val_acc, step=self.epoch_counter)\n",
    "\n",
    "            # Reset the training and validation metrics after every epoch\n",
    "            self.train_acc_metric.reset_states()\n",
    "            self.train_loss.reset_states()\n",
    "            self.val_acc_metric.reset_states()\n",
    "            self.val_loss.reset_states()\n",
    "\n",
    "            # Implement early stopping\n",
    "            wait += 1\n",
    "            if epoch_val_acc > best:\n",
    "                \n",
    "                self.best_epoch_counter = self.epoch_counter\n",
    "                best = epoch_val_acc\n",
    "                wait = 0\n",
    "\n",
    "                # Save the checkpoints only if the validation accuracy is the best observed\n",
    "                save_path = self.checkpoint_manager.save()\n",
    "                logger.info(f'[INFO] Saved checkpoint on epoch {self.epoch_counter} at: {save_path}')\n",
    "\n",
    "            if wait >= patience:\n",
    "\n",
    "                # Stop training once number of epochs without improvement exceeds patience\n",
    "                logger.info(f'[INFO] Executing early stopping at epoch {self.epoch_counter}, best val_accuracy seen: {best:0.2f} at epoch: {self.best_epoch_counter}')\n",
    "                break\n",
    "            \n",
    "            # Increment epoch counter by 1 at end of epoch\n",
    "            self.epoch_counter += 1\n",
    "    \n",
    "    def test(self, test_dataset, steps_per_epoch_test):\n",
    "\n",
    "        test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        test_loss = tf.keras.metrics.Mean(name='loss')\n",
    "\n",
    "        test_count = steps_per_epoch_test\n",
    "        for step, batch in enumerate(test_dataset):\n",
    "            if test_count == 0:\n",
    "                break\n",
    "            \n",
    "            step_loss, logits = self.predict_step(batch)\n",
    "            _, labels = batch\n",
    "\n",
    "            # Update the validation accuracy and loss\n",
    "            test_acc_metric.update_state(labels, logits)\n",
    "            test_loss.update_state(step_loss)\n",
    "            test_count -= 1\n",
    "\n",
    "        accuracy = test_acc_metric.result()\n",
    "        loss = test_loss.result()\n",
    "        \n",
    "        test_acc_metric.reset_states()\n",
    "        test_loss.reset_states()\n",
    "\n",
    "        return (accuracy, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the parameters and paths\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder paths containing the raw, extracted and tfrecords\n",
    "rawpath = r'../data/raw/pokemon.zip'\n",
    "datafolder = r'../data/extracted'\n",
    "tfrfolder = r'../data/tfrecords'\n",
    "\n",
    "# Define the paths to store the tfrecords\n",
    "train_path = os.path.join(*[os.pardir, 'data', 'tfrecords', 'train.tfrecord'])\n",
    "val_path = os.path.join(*[os.pardir, 'data', 'tfrecords', 'val.tfrecord'])\n",
    "test_path = os.path.join(*[os.pardir, 'data', 'tfrecords', 'test.tfrecord'])\n",
    "\n",
    "# Define the training parameters\n",
    "RANDOM_STATE = 42\n",
    "BATCHSIZE = 16 \n",
    "BUFFERSIZE = 250\n",
    "EPOCHS = 50 # Just set this as high as you like - there are implementations to stop training when appropriate\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "TRAIN_SIZE = 0.6\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2\n",
    "\n",
    "n_train = int(TRAIN_SIZE*250)\n",
    "n_val = int(VAL_SIZE*250)\n",
    "n_test = int(TEST_SIZE*250)\n",
    "\n",
    "steps_per_epoch_val = n_val // BATCHSIZE\n",
    "steps_per_epoch_test = n_test // BATCHSIZE\n",
    "steps_per_epoch_train = n_train // BATCHSIZE\n",
    "\n",
    "IMG_SIZE = [224, 224]\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "# Define the model save path\n",
    "save_path = '../models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise and execute the classes created\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to reset the files created in previous runs\n",
    "!rm -rf ../data/extracted/\n",
    "!rm -rf ../data/tfrecords/\n",
    "!rm -rf ./logs/\n",
    "!rm -rf ./tf_ckpts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data extraction and convert data into tfrecords\n",
    "dataextractor = DataExtractor(random_state=RANDOM_STATE, test_size=TEST_SIZE, val_size=VAL_SIZE)\n",
    "labels = dataextractor.extract_data(rawpath, datafolder)\n",
    "dataextractor.generate_tfrecords(tfrfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from tfrecords and perform data augmentation\n",
    "dataloader = DataLoader(img_size=IMG_SIZE, batch_size=BATCHSIZE, buffer_size=BUFFERSIZE, drop_remainder=True, random_seed=42)\n",
    "train_dataset, val_dataset, test_dataset = dataloader.read_tfrecords(train_path, val_path, test_path)\n",
    "\n",
    "# Plot the training images in TensorBoard\n",
    "img = dataloader.plot_train_images(steps=steps_per_epoch_train, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the model \n",
    "model = MyModel(n_classes=5)\n",
    "\n",
    "# Initialise the Model Trainer\n",
    "model_trainer = ModelTrainer(\n",
    "                          model=model, \n",
    "                          train_data=train_dataset, \n",
    "                          val_data=val_dataset, \n",
    "                          optimizer=optimizer, \n",
    "                          epochs=EPOCHS, \n",
    "                          steps_per_epoch_train=steps_per_epoch_train,\n",
    "                          steps_per_epoch_val=steps_per_epoch_val,\n",
    "                          labels=labels\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform training\n",
    "model_trainer.train_and_evaluate()\n",
    "\n",
    "# NOTE: \n",
    "# There are a couple of warnings and unrelated info automatically generated \n",
    "# by Tensorflow during training. Instead of relying on the console output, navigate to \n",
    "# Tensorboard to view the visualisations and metrics that are generated instead\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform error analysis with the use of TensorBoard\n",
    "---\n",
    "\n",
    "While the model is training, we can make use of TensorBoard to view the visualisations and metrics generated.  \n",
    "This includes the confusion matrix and error analysis plot that will be generated at the end of each epoch.  \n",
    "\n",
    "To run TensorBoard, run the code in any cell:\n",
    "```\n",
    "%tensorboard --logdir logs\n",
    "```\n",
    "In vscode, there might be some requirements to download extensions.  \n",
    "Download any extensions required, and once the code is executed a prompt might appear:  \n",
    "![image info](../unrelated_imgs/tensorboard_vscode.png)  \n",
    "\n",
    "Choose the option to 'select another folder', and choose the logs directory.  \n",
    "It might take sometime for the outputs to be generated as the model takes time to complete the first epoch.  \n",
    "\n",
    "There will be two tabs, one for the 'scalar', and one for the 'images'.  \n",
    "For this project, the output will be automatically generated at the end of each epoch and they can be refreshed during training by refreshing Tensorboard.  \n",
    "\n",
    "#### Scalar tab\n",
    "![image info](../unrelated_imgs/tensorboard_scalartab.png)  \n",
    "\n",
    "The scalar tab has been configured to show the train/val accuracy and loss at the end of each epoch.  \n",
    "This was mostly used to observe overfitting/underfitting and also as a sanity check to ensure that the model can actually learn.  \n",
    "\n",
    "#### Images tab\n",
    "![image info](../unrelated_imgs/tensorboard_imagetab.png)  \n",
    "\n",
    "The images tab is perhaps more important than the scalar tab as this was used to understand the model before and during training.  \n",
    "\n",
    "#### Training Images\n",
    "![image info](../unrelated_imgs/tensorboard_trainimg.png)  \n",
    "\n",
    "The training images plot shows us the images that are used in our model training.  \n",
    "Observing closely, there are a couple images with multiple pokemon in it, but they are mostly labelled as `squirtle`.  \n",
    "This is likely to affect the model as it might learn to classify images with multiple pokemon features as `squirtle`.  \n",
    "\n",
    "#### Confusion Matrix  \n",
    "![image info](../unrelated_imgs/tensorboard_cm.png)  \n",
    "\n",
    "This was mostly used to observe what the model is actually trying to do, and the training can be terminated early if the model starts becoming 'stupid'.  \n",
    "Initially there was a code bug which forces the model to only predict all images as 'squirtle', and fortunately this was discovered before wasting unnecessary time on training.  \n",
    "\n",
    "\n",
    "#### Error Analysis\n",
    "![image info](../unrelated_imgs/tensorboard_erroranalysis.png)  \n",
    "\n",
    "\n",
    "This is perhaps the most useful plot generated.  \n",
    "The plot shows all the misclassified images and the corresponding label predicted.  \n",
    "This is mainly used to get an understanding on where we might need to improve on our data collection.  \n",
    "For example, in the image above we can tell that the model is classifing images with multiple pokemon features as `squirtle`.  \n",
    "\n",
    "### Conclusion\n",
    "1. Observing the confusion matrix, it appears that the model is doing pretty well classifing `pikachu` and `mewtwo`.  \n",
    "2. The model also appears to have the tendency to misclassify some `bulbasaur` and `charmander` as `squirtle`, and this might be due to the inclusion of images  \n",
    "with all three pokemon labelled as `squirtle` in our training data.\n",
    "3. Looking at the misclassified images, the model appears to be classifying all images with multiple pokemons as `squirtle`.  This is understandable if we look back to  \n",
    "the training images, where we observe that the labels for images with multiple  pokemons are mostly `squirtle` as well.  \n",
    "\n",
    "One way to test the hypotheses above is to perhaps visualise the feature maps from the model layers.  \n",
    "One possible remedy is to remove the images with multiple pokemon from our dataset, and to focus on adding in images of  \n",
    "`squirtle`, `bulbasaur` and `charmander`.\n",
    "\n",
    "Due to time constraint, I am not able to perform the above two tasks prior to assignment submission.  \n",
    "Hyperparameter tuning on the model architecture and model hyperparameters was also not performed.  \n",
    "Only Resnet50 was used, and exploration of other feature extractors was not explored.  \n",
    "So these points may be considered as a 'next steps' or a shortcoming of the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform fine tuning \n",
    "---\n",
    "Aside from the points highlighted in the write up above, we can try to improve the model further by either: \n",
    "1. Data Augmentation (modify data), and/or\n",
    "2. Unfreezing some layers of the feature extractor and continue training  \n",
    "\n",
    "Data augmentation can be performed by uncommenting the codes in the `DataLoader` class and rerunning the whole project.  \n",
    "The model has also been designed to allow for fine tuning by continuing from the best checkpoint observed.  \n",
    "\n",
    "Here we will explore unfreezing some of the layers in ResNet50 for training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look at the overall structure of the model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete model consists of a resnet50 feature extractor and a dense layer on top of a global average pooling layer.  \n",
    "We can view the base model summary by explicitly calling on it  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_layers = model.base.layers\n",
    "print(f'Total layers in resnet50: {len(base_layers)}')\n",
    "model.base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text output might not be easy to understand for ResNet50 with residual blocks.  \n",
    "As such, we can try to plot the model instead.  \n",
    "\n",
    "There might be some requirements to install extensions in vscode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model.base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfreeze the layers from conv5_block3_1_conv layer onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.base.layers[165].name)\n",
    "\n",
    "for layer in model.base.layers[165:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconfigure the optimizer and continue training from where we left off  \n",
    "Notice that the training will continue from the previous best checkpoint and not from the last epoch trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might be a good idea to lower the learning rate to avoid overfitting\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE/10)\n",
    "\n",
    "# Initialise a new ModelTrainer with the new optimizer\n",
    "model_trainer.optimizer = optimizer\n",
    "\n",
    "# Continue training from where we left off earlier\n",
    "model_trainer.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to keep retraining for as many times as patience allows, given that we have implemented early stopping mechanism to stop the training  \n",
    "once no improvement has been observed for a number of epochs. Retraining will also continue off from the point where the model performance is highest,  \n",
    "and not from the last epoch trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the test set\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy, test_loss = model_trainer.test(test_dataset, steps_per_epoch_test)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:0.2f}')\n",
    "print(f'Test Loss: {test_loss:0.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a prediction on a single data\n",
    "---\n",
    "Keep rerunning the cell to generate predictions on different test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a single data from the test dataset\n",
    "for data in test_dataset.take(1).unbatch().as_numpy_iterator():\n",
    "    X, y = data\n",
    "    break\n",
    "\n",
    "batched_data = (X[np.newaxis, ...], y[np.newaxis, ...])\n",
    "_, logits = model_trainer.predict_step(batched_data)\n",
    "\n",
    "activated_logits = tf.nn.softmax(logits)\n",
    "pred = np.argmax(activated_logits)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.imshow(X/255.0)\n",
    "ax.set_title(f'Actual label: {labels[y]}')\n",
    "ax.set_axis_off()\n",
    "\n",
    "df = pd.DataFrame(labels, columns = ['pred_class'])\n",
    "df['confidence'] = activated_logits.numpy().reshape(5, 1)\n",
    "df = df.sort_values(by='confidence', ascending=False).reset_index(drop=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7f83ac078cfb58d9fcf8b9defa54c0ee020812932abc36d74ffd97a55e79614"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('dl_assignment': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
